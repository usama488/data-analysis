{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNYyWQZolHRlNTg+BZjhQeU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usama488/data-analysis/blob/main/notebooks/data_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "                       **About me**\n",
        "\n",
        "My name is Usama Bin Ali, and I am originally from Karak, Khyber Pakhtunkhwa, Pakistan. I have a strong academic background in the field of biological sciences, particularly bioinformatics, with a deep interest in omics technologies and clinical data analysis.\n",
        "\n",
        "I completed my Matriculation from Rashid Minhas Shaheed Public School, Mitha Khel, Karak, securing an A grade, followed by my F.Sc. (Pre-Medical) from Pearls Model College, Mitha Khel, Karak, also with an A grade.\n",
        "\n",
        "Afterward, I pursued my Bachelor’s degree in Bioinformatics at Khushal Khan Khattak University, Karak, graduating with a CGPA of 3.55. Currently, I am enrolled in an MPhil program in Bioinformatics at Hazara University, Mansehra, where I continue to build my expertise in data-driven life sciences.\n",
        "\n",
        "I am especially passionate about the application of bioinformatics in personalized medicine and healthcare, using omics and clinical datasets to solve complex biological problems."
      ],
      "metadata": {
        "id": "KmeZyWo9GrY0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code sets up everything needed for data analysis and visualization in Python. It imports useful libraries like pandas, NumPy, matplotlib, seaborn, and scikit-learn for working with data, making charts, and building simple models. The display settings are adjusted so that all rows and columns of a dataset can be seen clearly. It also applies a clean whitegrid style to make all charts look neat and easy to read."
      ],
      "metadata": {
        "id": "hiqZrvXKFcQm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dfd75d9",
        "outputId": "eb66f0c1-02e3-40f6-9a7e-0d3224232eb0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Set display options for pandas DataFrames\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Set a clean visualization style for matplotlib and seaborn\n",
        "plt.style.use('seaborn-v0_8-whitegrid') # Using a seaborn style\n",
        "sns.set_theme(style=\"whitegrid\") # Setting seaborn theme\n",
        "\n",
        "print(\"Libraries imported, display options set, and visualization style applied.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported, display options set, and visualization style applied.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code block is used to load a dataset and check its basic details. It tries to read a CSV file named your_dataset.csv using pandas. If the file is found, it shows the shape of the dataset, the first five rows, and the data types of each column. If the file is missing, it shows an error message and sets df to None to prevent further issues."
      ],
      "metadata": {
        "id": "ineEFGTTu6fD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1afce98",
        "outputId": "60cc1fd5-8bd3-4d4f-90f1-b8a83201a993"
      },
      "source": [
        "# Data Loading\n",
        "try:\n",
        "    df = pd.read_csv('your_dataset.csv')\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "\n",
        "    print(\"\\nDataset Shape:\")\n",
        "    display(df.shape)\n",
        "\n",
        "    print(\"\\nFirst 5 rows of the dataset:\")\n",
        "    display(df.head())\n",
        "\n",
        "    print(\"\\nData Types:\")\n",
        "    display(df.dtypes)\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'your_dataset.csv' not found. Please make sure the file is in the correct directory or provide the full path.\")\n",
        "    df = None # Set df to None if file not found"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 'your_dataset.csv' not found. Please make sure the file is in the correct directory or provide the full path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code cleans the dataset to prepare it for analysis. It first checks if the data was loaded successfully. Then, it looks for missing values and fills them — using the mean for numeric columns and the most frequent value (mode) for categorical ones. Next, it removes duplicate rows to avoid repeated information. If the dataset has any columns named ‘date’ or ‘datetime’, those are converted to proper datetime format. Finally, it shows the updated data types and creates a cleaned copy of the dataset for further analysis."
      ],
      "metadata": {
        "id": "6dGg5GGOvN-B"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2b15fe7",
        "outputId": "22a65be3-f029-44a6-8d06-0dcd82b5faa1"
      },
      "source": [
        "# Data Cleaning\n",
        "\n",
        "if df is not None:\n",
        "    print(\"Original dataset shape:\", df.shape)\n",
        "\n",
        "    # Check for missing values\n",
        "    print(\"\\nMissing values before cleaning:\")\n",
        "    display(df.isnull().sum())\n",
        "\n",
        "    # Handle missing values (example: fill numerical with mean, categorical with mode)\n",
        "    for col in df.columns:\n",
        "        if df[col].isnull().any():\n",
        "            if df[col].dtype in ['int64', 'float64']:\n",
        "                df[col].fillna(df[col].mean(), inplace=True)\n",
        "            else:\n",
        "                df[col].fillna(df[col].mode()[0], inplace=True)\n",
        "\n",
        "    print(\"\\nMissing values after handling:\")\n",
        "    display(df.isnull().sum())\n",
        "\n",
        "    # Drop duplicate rows\n",
        "    initial_rows = df.shape[0]\n",
        "    df.drop_duplicates(inplace=True)\n",
        "    rows_after_dropping_duplicates = df.shape[0]\n",
        "    print(f\"\\nNumber of duplicate rows dropped: {initial_rows - rows_after_dropping_duplicates}\")\n",
        "    print(\"Dataset shape after dropping duplicates:\", df.shape)\n",
        "\n",
        "\n",
        "    # Convert 'date' and 'datetime' columns to datetime objects\n",
        "    for col in df.columns:\n",
        "        if col.lower() == 'date' or col.lower() == 'datetime':\n",
        "            try:\n",
        "                df[col] = pd.to_datetime(df[col], errors='coerce')\n",
        "                print(f\"\\nConverted '{col}' to datetime.\")\n",
        "                # Handle any values that couldn't be converted (they will be NaT - Not a Time)\n",
        "                if df[col].isnull().any():\n",
        "                    print(f\"Warning: Some values in '{col}' could not be converted to datetime and were set to NaT.\")\n",
        "                    # You might want to handle these NaT values further, e.g., drop rows or fill with a placeholder\n",
        "            except Exception as e:\n",
        "                print(f\"Could not convert column '{col}' to datetime: {e}\")\n",
        "\n",
        "    print(\"\\nData Types after cleaning:\")\n",
        "    display(df.dtypes)\n",
        "\n",
        "    df_cleaned = df.copy() # Create a cleaned copy for further steps\n",
        "    print(\"\\nData Cleaning steps completed.\")\n",
        "    print(\"\\nFirst 5 rows of the cleaned dataset:\")\n",
        "    display(df_cleaned.head())\n",
        "\n",
        "else:\n",
        "    print(\"Data has not been loaded successfully. Please load the data first.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has not been loaded successfully. Please load the data first.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code performs basic Exploratory Data Analysis (EDA) on a cleaned dataset called df_cleaned. It displays summary statistics, plots a histogram to show the distribution of the first numeric column, and creates a correlation heatmap to visualize relationships between numeric variables. It also generates a boxplot to detect outliers. If the dataset isn’t loaded properly, it prompts the user to load and clean the data first."
      ],
      "metadata": {
        "id": "3AQf46Ihvm3G"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e689719e",
        "outputId": "ba974c35-f5b8-4d98-c15f-7c3a2f258df1"
      },
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "\n",
        "if 'df_cleaned' in locals() and df_cleaned is not None:\n",
        "    print(\"\\nSummary Statistics:\")\n",
        "    display(df_cleaned.describe())\n",
        "\n",
        "    # Histogram of a numeric column (replace 'your_numeric_column' with an actual column name)\n",
        "    numeric_cols = df_cleaned.select_dtypes(include=np.number).columns\n",
        "    if not numeric_cols.empty:\n",
        "        col_to_plot = numeric_cols[0] # Use the first numeric column found\n",
        "        print(f\"\\nHistogram of '{col_to_plot}':\")\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        sns.histplot(df_cleaned[col_to_plot], kde=True)\n",
        "        plt.title(f'Distribution of {col_to_plot}')\n",
        "        plt.xlabel(col_to_plot)\n",
        "        plt.ylabel('Frequency')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"\\nNo numeric columns found for histogram.\")\n",
        "\n",
        "\n",
        "    print(\"\\nCorrelation Heatmap:\")\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    # Select only numerical columns for correlation heatmap\n",
        "    df_numeric = df_cleaned.select_dtypes(include=np.number)\n",
        "    if not df_numeric.empty:\n",
        "        sns.heatmap(df_numeric.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "        plt.title('Correlation Heatmap')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"\\nNo numeric columns found for correlation heatmap.\")\n",
        "\n",
        "\n",
        "    # Boxplot to detect outliers (replace 'your_numeric_column' with an actual column name)\n",
        "    if not numeric_cols.empty:\n",
        "        col_to_plot_boxplot = numeric_cols[0] # Use the first numeric column found\n",
        "        print(f\"\\nBoxplot of '{col_to_plot_boxplot}' to detect outliers:\")\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        sns.boxplot(x=df_cleaned[col_to_plot_boxplot])\n",
        "        plt.title(f'Boxplot of {col_to_plot_boxplot}')\n",
        "        plt.xlabel(col_to_plot_boxplot)\n",
        "        plt.show()\n",
        "    else:\n",
        "         print(\"\\nNo numeric columns found for boxplot.\")\n",
        "\n",
        "    print(\"\\nExploratory Data Analysis steps completed.\")\n",
        "\n",
        "else:\n",
        "    print(\"Data has not been loaded and cleaned successfully. Please load and clean the data first.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has not been loaded and cleaned successfully. Please load and clean the data first.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code performs feature engineering on the cleaned dataset df_cleaned. It first creates a new feature called profitmargin, calculated as the ratio of profit to revenue (avoiding division by zero). Then, it checks for any datetime columns and extracts the month from each into new columns (e.g., date_month). Finally, it displays the first five rows of the updated dataset and saves a copy as df_featured. If the data isn’t loaded properly, it prompts the user to load and clean it first."
      ],
      "metadata": {
        "id": "yaiihZjcxhwY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebd3513b",
        "outputId": "692c4d12-c502-4d78-d44e-31074582e4e3"
      },
      "source": [
        "# Feature Engineering\n",
        "\n",
        "if 'df_cleaned' in locals() and df_cleaned is not None:\n",
        "    # Create 'profitmargin' feature\n",
        "    # Ensure 'revenue' is not zero to avoid division by zero\n",
        "    if 'profit' in df_cleaned.columns and 'revenue' in df_cleaned.columns:\n",
        "        df_cleaned['profitmargin'] = np.where(df_cleaned['revenue'] != 0, df_cleaned['profit'] / df_cleaned['revenue'], 0)\n",
        "        print(\"\\n'profitmargin' feature created.\")\n",
        "    else:\n",
        "        print(\"\\nCould not create 'profitmargin' feature. Make sure 'profit' and 'revenue' columns exist.\")\n",
        "\n",
        "    # Extract month from any datetime column\n",
        "    datetime_cols = df_cleaned.select_dtypes(include='datetime64[ns]').columns\n",
        "    if not datetime_cols.empty:\n",
        "        for col in datetime_cols:\n",
        "            df_cleaned[f'{col}_month'] = df_cleaned[col].dt.month\n",
        "            print(f\"\\nExtracted month from '{col}' into a new column '{col}_month'.\")\n",
        "    else:\n",
        "        print(\"\\nNo datetime columns found to extract month from.\")\n",
        "\n",
        "    print(\"\\nFirst 5 rows of the updated dataset with new features:\")\n",
        "    display(df_cleaned.head())\n",
        "\n",
        "    df_featured = df_cleaned.copy() # Create a copy after feature engineering\n",
        "    print(\"\\nFeature Engineering steps completed.\")\n",
        "\n",
        "else:\n",
        "    print(\"Data has not been loaded and cleaned successfully. Please load and clean the data first.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has not been loaded and cleaned successfully. Please load and clean the data first.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code performs model selection and training using a Linear Regression model. It assumes that ‘Advertising’ is the independent variable (X) and ‘Revenue’ is the dependent variable (y). The dataset is split into training (80%) and testing (20%) sets, after which a linear regression model is trained on the training data. The script then displays the model’s intercept and coefficient, which represent the relationship between advertising spending and revenue. If the required columns or dataset are missing, it prints appropriate error messages."
      ],
      "metadata": {
        "id": "tIcR2xJ-xu0i"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2049215",
        "outputId": "bf5b6535-c78e-4f0c-ed66-4d25917b7b7b"
      },
      "source": [
        "# Model Selection and Training (Linear Regression)\n",
        "\n",
        "if 'df_featured' in locals() and df_featured is not None:\n",
        "    # Assuming 'Advertising' is your independent variable (X) and 'Revenue' is your dependent variable (y)\n",
        "    # Replace 'Advertising' and 'Revenue' with your actual column names\n",
        "    try:\n",
        "        X = df_featured[['Advertising']] # Independent variable(s)\n",
        "        y = df_featured['Revenue'] # Dependent variable\n",
        "\n",
        "        # Split data into training and testing sets (80/20 split)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        print(\"Data split into training and testing sets.\")\n",
        "        print(f\"Training set shape (X_train, y_train): {X_train.shape}, {y_train.shape}\")\n",
        "        print(f\"Testing set shape (X_test, y_test): {X_test.shape}, {y_test.shape}\")\n",
        "\n",
        "        # Initialize and train the Linear Regression model\n",
        "        model = LinearRegression()\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        print(\"\\nLinear Regression model trained successfully.\")\n",
        "        print(f\"Model Intercept: {model.intercept_:.2f}\")\n",
        "        print(f\"Model Coefficient (for Advertising): {model.coef_[0]:.2f}\")\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: Make sure you have columns named 'Advertising' and 'Revenue' in your dataframe. Details: {e}\")\n",
        "    except NameError:\n",
        "         print(\"Error: 'df_featured' is not defined. Please run the data loading, cleaning, and feature engineering steps first.\")\n",
        "else:\n",
        "    print(\"Data has not been loaded and featured successfully. Please check the previous steps.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has not been loaded and featured successfully. Please check the previous steps.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code evaluates the performance of the trained Linear Regression model. It first makes predictions on the test dataset (X_test) and then calculates two key evaluation metrics: Mean Squared Error (MSE), which measures the average squared difference between predicted and actual values, and R² Score, which indicates how well the model explains the variability of the target variable. The results are printed for review. If the model or test data is missing, appropriate error messages are displayed."
      ],
      "metadata": {
        "id": "S6obF_bjx766"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6466a332",
        "outputId": "eeed6d9f-800e-421a-9f9a-44492b68af4e"
      },
      "source": [
        "# Model Evaluation\n",
        "\n",
        "if 'model' in locals() and 'X_test' in locals() and 'y_test' in locals():\n",
        "    try:\n",
        "        # Predict on the test set\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Calculate Mean Squared Error\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "        # Calculate R2 Score\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        print(\"\\nModel Evaluation Metrics:\")\n",
        "        print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "        print(f\"R2 Score: {r2:.2f}\")\n",
        "\n",
        "    except NameError:\n",
        "        print(\"Error: Model or test data not found. Please ensure the Model Selection and Training step was completed successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during model evaluation: {e}\")\n",
        "else:\n",
        "    print(\"Model and test data are not available for evaluation. Please ensure the Model Selection and Training step was completed successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and test data are not available for evaluation. Please ensure the Model Selection and Training step was completed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code creates a scatter plot to visually compare the actual revenue (y_test) with the predicted revenue (y_pred) from the model. Each point on the plot represents a data record, showing how close the predictions are to the true values — points lying near the diagonal line indicate accurate predictions. The plot helps assess model performance visually. If the required data isn’t available, it prints an error message prompting the user to complete the model evaluation step first."
      ],
      "metadata": {
        "id": "YsAP0KknyKfu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ac50356",
        "outputId": "4012c1a6-5586-4548-8673-9cb7c1a42779"
      },
      "source": [
        "# Scatter plot of actual vs predicted revenue\n",
        "\n",
        "if 'y_test' in locals() and 'y_pred' in locals():\n",
        "    try:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.scatter(y_test, y_pred, alpha=0.5)\n",
        "        plt.xlabel(\"Actual Revenue\")\n",
        "        plt.ylabel(\"Predicted Revenue\")\n",
        "        plt.title(\"Actual vs Predicted Revenue\")\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while creating the scatter plot: {e}\")\n",
        "else:\n",
        "    print(\"Actual and predicted values are not available for plotting. Please ensure the Model Evaluation step was completed successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual and predicted values are not available for plotting. Please ensure the Model Evaluation step was completed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d0a10aa"
      },
      "source": [
        "## Analysis Summary and Key Insights\n",
        "\n",
        "This analysis aimed to understand the relationship between advertising and revenue and to build a linear regression model to predict revenue based on advertising spend.\n",
        "\n",
        "**Key Findings:**\n",
        "\n",
        "*   **Data Overview:** The dataset contained [Number] rows and [Number] columns. Initial data loading showed [Mention any initial observations, e.g., file not found issue].\n",
        "*   **Data Cleaning:** Missing values were handled by [Explain how missing values were handled, e.g., filling with mean/mode]. Duplicate rows were [Mention if duplicates were dropped and how many]. Data types were [Mention any conversions, e.g., date columns to datetime].\n",
        "*   **Exploratory Data Analysis (EDA):**\n",
        "    *   Summary statistics revealed [Mention any interesting statistics like mean, median, standard deviation for key columns].\n",
        "    *   The distribution of [Numeric Column Name] showed [Describe the distribution, e.g., skewed, normal].\n",
        "    *   The correlation heatmap indicated [Describe key correlations, especially between advertising and revenue].\n",
        "    *   Boxplots for [Numeric Column Name] showed [Mention presence or absence of outliers].\n",
        "*   **Feature Engineering:** A new feature, `profitmargin`, was created as [Explain the calculation]. Month was extracted from [Date Column Name].\n",
        "*   **Model Performance:**\n",
        "    *   The Linear Regression model trained to predict Revenue from Advertising resulted in an R2 score of [Your R2 Score]. This indicates that [Interpret the R2 score, e.g., X% of the variance in Revenue can be explained by Advertising].\n",
        "    *   The Mean Squared Error (MSE) of the model was [Your MSE Value]. This metric represents [Explain what MSE means in this context].\n",
        "    *   The scatter plot of actual vs. predicted revenue values [Describe the plot, e.g., shows a clear linear trend, points are clustered around the line].\n",
        "*   **Business Recommendations:** Based on this analysis, some recommendations could include:\n",
        "    *   [Example: Increase advertising spend as there appears to be a positive correlation with revenue].\n",
        "    *   [Example: Investigate outliers in [Column Name] as they might represent important events or data errors].\n",
        "    *   [Example: Explore other features that might impact revenue based on correlations observed in EDA].\n",
        "    *   [Any other relevant recommendations based on your specific data and business context].\n",
        "\n",
        "**Next Steps:**\n",
        "\n",
        "*   [Example: Explore more advanced regression models].\n",
        "*   [Example: Gather more data on other potential factors influencing revenue].\n",
        "*   [Example: Monitor the performance of the implemented recommendations]."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "This code saves the cleaned dataset (df_cleaned) to a CSV file for future use. It first defines a directory (data/processed) and filename (cleaned_sales.csv), then creates the directory if it doesn’t already exist. The cleaned DataFrame is saved as a CSV file at the specified location without including the index column. If the dataset is missing or an error occurs during saving, the code prints an appropriate error message."
      ],
      "metadata": {
        "id": "ZxzMqG3VyZBh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "946f7910",
        "outputId": "cff0a12d-f55a-4c23-acf1-ae4c66c792cd"
      },
      "source": [
        "import os\n",
        "\n",
        "# Define the directory and filename\n",
        "output_dir = 'data/processed'\n",
        "output_filename = 'cleaned_sales.csv'\n",
        "output_path = os.path.join(output_dir, output_filename)\n",
        "\n",
        "if 'df_cleaned' in locals() and df_cleaned is not None:\n",
        "    try:\n",
        "        # Create the output directory if it doesn't exist\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Save the cleaned dataframe to CSV\n",
        "        df_cleaned.to_csv(output_path, index=False)\n",
        "\n",
        "        print(f\"Cleaned dataframe successfully saved to '{output_path}'\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while saving the dataframe: {e}\")\n",
        "else:\n",
        "    print(\"Cleaned dataframe ('df_cleaned') not found. Please ensure the data cleaning step was completed successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned dataframe ('df_cleaned') not found. Please ensure the data cleaning step was completed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nEfQ8JfS0Aif"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}